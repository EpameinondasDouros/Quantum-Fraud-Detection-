{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5JSOGQYbQMIeP0rfOoyMq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Installs"],"metadata":{"id":"7TZQt-lp6Zro"}},{"cell_type":"code","source":["!pip install tensorflow==2.8.1"],"metadata":{"id":"A3vM84HCfWgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install protobuf==3.20.3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"LvbEYF_JgMGH","executionInfo":{"status":"ok","timestamp":1732188894863,"user_tz":-120,"elapsed":10794,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"86d94cd0-4dca-4b51-b2bd-a7c6aec001a9"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting protobuf==3.20.3\n","  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n","Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 4.25.5\n","    Uninstalling protobuf-4.25.5:\n","      Successfully uninstalled protobuf-4.25.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n","pandas-gbq 0.24.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.8.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed protobuf-3.20.3\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]},"id":"adb22cb4428d4e5eb83b3f4ec1c35e0c"}},"metadata":{}}]},{"cell_type":"code","execution_count":1,"metadata":{"id":"WcCoTWvNiJoH","executionInfo":{"status":"ok","timestamp":1732188917397,"user_tz":-120,"elapsed":8125,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pennylane as qml\n","from pennylane import numpy as np\n","from tensorflow.keras.models import Model, Sequential"]},{"cell_type":"code","source":["!pip install pennylane"],"metadata":{"id":"tEBDeWalkjSJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install the Kaggle library\n","!pip install kaggle\n","\n","# Upload kaggle.json file\n","from google.colab import files\n","files.upload()  # This will prompt you to upload kaggle.json\n","\n","# Make a directory for Kaggle and move the file there\n","!mkdir -p ~/.kaggle\n","!mv kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json\n","\n","# Now you can download the dataset\n","!kaggle datasets download -d mlg-ulb/creditcardfraud -p /content/datasets --unzip\n","\n","print(\"Dataset downloaded to: /content/datasets\")"],"metadata":{"id":"KcI_g_wliKSq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"FuSC8slEkAf-"}},{"cell_type":"code","source":["finance_df=pd.read_csv(\"/content/datasets/creditcard.csv\",delimiter=',')"],"metadata":{"id":"QyVAulWTiLUt","executionInfo":{"status":"error","timestamp":1732184194395,"user_tz":-120,"elapsed":571,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"55964c18-ed41-4454-fee5-cf4504f809e7"},"execution_count":25,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-f15cc277ae2c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinance_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/datasets/creditcard.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"cell_type":"code","source":["finance_df.describe()"],"metadata":{"id":"cH9_xgociO2k","colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"status":"error","timestamp":1732184194815,"user_tz":-120,"elapsed":50,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"d6c8de61-3fc3-4eb2-aa07-37e982e43279"},"execution_count":26,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'finance_df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-5cd1bc3a6d5b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinance_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'finance_df' is not defined"]}]},{"cell_type":"code","source":["df=finance_df"],"metadata":{"id":"NopMUpoOjCpS","executionInfo":{"status":"aborted","timestamp":1732184194816,"user_tz":-120,"elapsed":43,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","train_size = 0.7  # 70% for training\n","test_size = 0.15  # 15% for testing\n","validation_size = 0.15  # 15% for validation\n","\n","# First split: Train and temp (temp is a placeholder for validation + test)\n","train_df, temp_df = train_test_split(df, test_size=(test_size + validation_size), random_state=42)\n","\n","# Second split: Split the temp set into validation and test\n","validation_df, test_df = train_test_split(temp_df, test_size=test_size / (test_size + validation_size), random_state=42)\n","\n","# Output the splits\n","print(f\"Train set size: {len(train_df)}\")\n","print(f\"Validation set size: {len(validation_df)}\")\n","print(f\"Test set size: {len(test_df)}\")"],"metadata":{"id":"dIWIcbzaiPVV","executionInfo":{"status":"aborted","timestamp":1732184194817,"user_tz":-120,"elapsed":43,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = train_df['Class']\n","x_train = train_df.drop(['Class'], axis=1)\n","y_validation = validation_df ['Class']\n","x_validation = validation_df.drop(['Class'], axis=1)\n","y_test = test_df['Class']\n","x_test = test_df.drop(['Class'], axis=1)"],"metadata":{"id":"rS8qA3e0iipC","executionInfo":{"status":"aborted","timestamp":1732184194818,"user_tz":-120,"elapsed":42,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder,StandardScaler\n","import tensorflow as tf"],"metadata":{"id":"44IHESYojjKX","executionInfo":{"status":"aborted","timestamp":1732184194818,"user_tz":-120,"elapsed":41,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lbl_clf = LabelEncoder()\n","y_train = lbl_clf.fit_transform(y_train)\n","y_train = tf.keras.utils.to_categorical(y_train)"],"metadata":{"id":"l00S-bXhi_vS","executionInfo":{"status":"aborted","timestamp":1732184194819,"user_tz":-120,"elapsed":40,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["std_clf = StandardScaler()\n","x_train = std_clf.fit_transform(x_train)\n","x_validation = std_clf.fit_transform(x_validation)\n","x_test = std_clf.transform(x_test)"],"metadata":{"id":"4DcgZyaojbRC","executionInfo":{"status":"aborted","timestamp":1732184194820,"user_tz":-120,"elapsed":40,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"UQk8UesUkI5B","executionInfo":{"status":"aborted","timestamp":1732184194821,"user_tz":-120,"elapsed":38,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model\n"],"metadata":{"id":"wwFSo39RFurC"}},{"cell_type":"markdown","source":["Now we start initializing the Quantum Circuit\n","\n","In the following code we can change the defauly_qubit to AWS services by using the following commands:\n","\n","device_arn = \"arn:aws:braket:eu-west-2::device/qpu/ionq/Aria-1\"\n","dev = qml.device('braket.aws.qubit',device_arn=device_arn, wires=num_wires)"],"metadata":{"id":"P3O00PNnkSrz"}},{"cell_type":"markdown","source":[],"metadata":{"id":"aHsk188HFtCN"}},{"cell_type":"code","source":[],"metadata":{"id":"EqEFYw0JklYq","executionInfo":{"status":"error","timestamp":1732188797368,"user_tz":-120,"elapsed":7597,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"colab":{"base_uri":"https://localhost:8080/","height":443},"outputId":"5b10d705-2590-4191-9d18-2c3aa5a43922"},"execution_count":3,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-ba0890371708>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# pylint: enable=wildcard-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunction_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoordination_config_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/framework/function_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mattr_value_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_attr__value__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnode_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_node__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mop_def_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_op__def__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/framework/attr_value_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/framework/tensor_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresource_handle_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_resource__handle__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/framework/resource_handle_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor_shape_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtensorflow_dot_core_dot_framework_dot_types__pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/framework/tensor_shape_pb2.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mcontaining_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m   fields=[\n\u001b[0;32m---> 36\u001b[0;31m     _descriptor.FieldDescriptor(\n\u001b[0m\u001b[1;32m     37\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tensorflow.TensorShapeProto.Dim.size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpp_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 \u001b[0mhas_default_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontaining_oneof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                 file=None, create_key=None):  # pylint: disable=redefined-builtin\n\u001b[0;32m--> 553\u001b[0;31m       \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_CheckCalledFromGeneratedFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFindExtensionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"]}]},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"cWGWAVFOH7Rw","executionInfo":{"status":"ok","timestamp":1732188924854,"user_tz":-120,"elapsed":333,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.layers import Dense, Dropout\n","\n","hidden = Dense(32, activation =\"relu\", kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n","out_2 = Dense(9, activation =\"relu\", kernel_initializer='he_normal', kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001))\n","do = Dropout(0,3)"],"metadata":{"id":"s-W7SKgDjrep","executionInfo":{"status":"ok","timestamp":1732188928940,"user_tz":-120,"elapsed":529,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["num_wires = 3\n","dev = qml.device('default.qubit', wires=num_wires)"],"metadata":{"id":"vddxHanbj7j8","executionInfo":{"status":"ok","timestamp":1732188929772,"user_tz":-120,"elapsed":14,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\n","def quantum_nn(inputs, weights):\n","    # print(inputs)\n","    # print(inputs[2])\n","    qml.RY(inputs[0], wires=0)\n","    qml.RY(inputs[1], wires=1)\n","    qml.RY(inputs[2], wires=2)\n","    qml.Rot(weights[0] * inputs[3], weights[1] * inputs[4], weights[2] * inputs[5], wires=1)\n","    qml.Rot(weights[3] * inputs[6], weights[4] * inputs[7], weights[5] * inputs[8], wires=2)\n","    qml.CNOT(wires=[1, 2])\n","    qml.RY(weights[6], wires=2)\n","    qml.CNOT(wires=[0, 2])\n","    qml.CNOT(wires=[1, 2])\n","    # print(\"Now we are returning the evaluations: \")\n","    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(2))]"],"metadata":{"id":"YsrfPqOqkinj","executionInfo":{"status":"ok","timestamp":1732188978191,"user_tz":-120,"elapsed":310,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Understanding and testing the quantum circuit"],"metadata":{"id":"TbJ8agPpF3Ux"}},{"cell_type":"code","source":["# Prepare dummy input data and weights\n","inputs = tf.constant([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], dtype=tf.float64)\n","weights = tf.Variable([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7], dtype=tf.float64)"],"metadata":{"id":"YjKewRSsF9rX","executionInfo":{"status":"ok","timestamp":1732188934169,"user_tz":-120,"elapsed":57,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["outputs = quantum_nn(inputs, weights)\n","probs = [tf.constant((output + 1) / 2) for output in outputs]\n","softmax_outputs = tf.nn.softmax(outputs)\n","\n","print(\"Softmax Outputs:\", softmax_outputs)\n","print(\"Normalized Outputs:\", probs)\n","print(\"Untouched Outputs:\", outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YSWVmEKdIJGc","executionInfo":{"status":"ok","timestamp":1732188934170,"user_tz":-120,"elapsed":52,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"2ae662a5-ce3e-49cc-bf8f-3ec79d48445d"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9], shape=(9,), dtype=float64)\n","tf.Tensor(0.3, shape=(), dtype=float64)\n","Now we are returning the evaluations: \n","Softmax Outputs: tf.Tensor([0.6718629 0.3281371], shape=(2,), dtype=float64)\n","Normalized Outputs: [<tf.Tensor: shape=(), dtype=float64, numpy=0.9975020826390127>, <tf.Tensor: shape=(), dtype=float64, numpy=0.6391906937035146>]\n","Untouched Outputs: [<tf.Tensor: shape=(), dtype=float64, numpy=0.9950041652780255>, <tf.Tensor: shape=(), dtype=float64, numpy=0.2783813874070292>]\n"]}]},{"cell_type":"markdown","source":["Even though we implemented some reguralization techniques, for now we are going to use the outputs as they are given back from the circuit"],"metadata":{"id":"TJOgwXCERcqe"}},{"cell_type":"code","source":["threshold = 0.5\n","binary_probs = [tf.constant(1 if output > threshold else 0) for output in outputs]\n","\n","print(binary_probs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfkGqWiJMtZJ","executionInfo":{"status":"ok","timestamp":1732188934171,"user_tz":-120,"elapsed":43,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"877c492e-6555-4e37-b859-079fa75e422d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[<tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=0>]\n"]}]},{"cell_type":"code","source":["# def loss_fn(inputs, weights, targets):\n","#     # Compute outputs for the batch\n","#     outputs = [quantum_nn(input_sample, weights) for input_sample in inputs]  # Outputs: [batch_size, num_classes]\n","\n","#     # Threshold to get binary probabilities\n","#     threshold = 0.5\n","#     binary_probs = [\n","#         [1.0 if output > threshold else 0.0 for output in record]\n","#         for record in outputs\n","#     ]\n","\n","#     # Convert binary_probs to a proper tensor\n","#     binary_probs = tf.constant(binary_probs, dtype=tf.float64)\n","\n","#     print(\"Binary Probabilities:\", binary_probs)\n","\n","#     # Map binary probabilities to class labels\n","#     predicted_labels = [1 if prob[1] == 1.0 else 0 for prob in binary_probs]\n","#     predicted_labels=tf.cast(predicted_labels,dtype=tf.float64)\n","#     print(\"Predicted Labels:\", predicted_labels)\n","#     # Ensure targets are also tensors of the same dtype\n","#     targets = tf.cast(targets, dtype=tf.float64)\n","\n","#     print(targets)\n","\n","#     # Compute binary cross-entropy loss\n","\n","#     loss = tf.keras.losses.binary_crossentropy(targets, predicted_labels)\n","#     return tf.reduce_mean(loss)\n"],"metadata":{"id":"46rdJEjHR4mF","executionInfo":{"status":"ok","timestamp":1732188934172,"user_tz":-120,"elapsed":31,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import warnings\n","\n","\n","def loss_fn(inputs, weights, targets):\n","    # Compute outputs for the batch\n","    outputs = [quantum_nn(input_sample, weights) for input_sample in inputs]  # Raw continuous outputs\n","\n","    softmax_outputs = tf.nn.softmax(outputs)\n","\n","    # Convert to tensor\n","    outputs = tf.convert_to_tensor(softmax_outputs, dtype=tf.float64)\n","\n","    # print(\"Raw Outputs:\", outputs)\n","\n","    # Ensure targets are tensors of the same dtype\n","    targets = tf.cast(targets, dtype=tf.float64)\n","\n","    # Compute binary cross-entropy loss directly on raw outputs\n","    warnings.filterwarnings(\"ignore\")\n","    loss = tf.keras.losses.binary_crossentropy(targets, outputs)\n","    return tf.reduce_mean(loss)\n"],"metadata":{"id":"Pw2BxjRVa-ZQ","executionInfo":{"status":"ok","timestamp":1732188955517,"user_tz":-120,"elapsed":282,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","\n","# Generate 150 samples of 8-dimensional inputs\n","inputs = tf.constant(np.random.rand(1500, 9), dtype=tf.float64)\n","\n","# Generate 150 one-hot encoded targets (binary classification)\n","binary_labels = np.random.choice([0, 1], size=(1500,))\n","targets = tf.constant([[1, 0] if label == 0 else [0, 1] for label in binary_labels], dtype=tf.float64)\n","\n","print(\"Inputs shape:\", inputs.shape)\n","print(\"Targets shape:\", targets.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i11DzFCwgnVi","executionInfo":{"status":"ok","timestamp":1732189705463,"user_tz":-120,"elapsed":408,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"0f215665-f8ff-44b1-c36c-542c8393cb0e"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs shape: (1500, 9)\n","Targets shape: (1500, 2)\n"]}]},{"cell_type":"code","source":["weights = tf.Variable([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8], dtype=tf.float64)\n","\n","\n","# Forward pass\n","loss_value = loss_fn(inputs, weights, targets)\n","\n","print(\"Loss Value:\", loss_value.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SARQxH1RKLgR","executionInfo":{"status":"ok","timestamp":1732189750735,"user_tz":-120,"elapsed":44972,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"14c116b4-8941-47dd-9cad-b4060720f6b8"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss Value: 0.7696314555729998\n"]}]},{"cell_type":"code","source":["# Compute gradients\n","with tf.GradientTape() as tape:\n","    tape.watch(weights)  # Ensure weights are tracked\n","    loss_value = loss_fn(inputs, weights, targets)\n","\n","# Compute gradient of loss with respect to weights\n","grads = tape.gradient(loss_value, weights)\n","\n","print(\"Loss:\", loss_value.numpy())\n","print(\"Gradients:\", grads.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hS4bwjJYYQyd","executionInfo":{"status":"ok","timestamp":1732189104699,"user_tz":-120,"elapsed":9098,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"6aa98b04-e286-4f32-ea45-64f5d384ffa1"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Loss: 0.8010057081914876\n","Gradients: [ 5.52254811e-05 -1.89640936e-02 -1.26185200e-18 -1.65395865e-02\n","  9.50913059e-02 -1.87721798e-02  1.51683186e-01  0.00000000e+00]\n"]}]},{"cell_type":"code","source":["# Set up the optimizer\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"],"metadata":{"id":"qzxoB6gqdItn","executionInfo":{"status":"ok","timestamp":1732189104700,"user_tz":-120,"elapsed":22,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Number of training epochs\n","epochs = 10  # Adjust as needed\n","\n","# Training loop\n","for epoch in range(epochs):\n","    with tf.GradientTape() as tape:\n","        loss = loss_fn(inputs, weights, targets)\n","    grads = tape.gradient(loss, weights)\n","    optimizer.apply_gradients(zip([grads], [weights]))\n","    print(f\"Epoch {epoch + 1}, Loss: {loss.numpy()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuoxWyvZdThk","executionInfo":{"status":"ok","timestamp":1732190551243,"user_tz":-120,"elapsed":114708,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"fe131dfd-cc51-4795-8013-8a1fc3e2e97e"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 0.7696314555729998\n","Epoch 2, Loss: 0.7684706800371814\n","Epoch 3, Loss: 0.7669225819735259\n","Epoch 4, Loss: 0.7651355173740946\n","Epoch 5, Loss: 0.7631910215346874\n","Epoch 6, Loss: 0.7611427433521127\n","Epoch 7, Loss: 0.7590291133218525\n","Epoch 8, Loss: 0.7568790305100238\n","Epoch 9, Loss: 0.7547148906430472\n","Epoch 10, Loss: 0.7525543822112587\n"]}]},{"cell_type":"markdown","source":["## Now implementing hybrid model"],"metadata":{"id":"7kVdQ4FBF3yv"}},{"cell_type":"code","source":["def hybrid_model(num_layers, num_wires):\n","    weight_shapes = {\"weights\": (7,)}\n","    print(weight_shapes)\n","    qlayer = qml.qnn.KerasLayer(quantum_nn, weight_shapes, output_dim=2)\n","    hybrid_model = tf.keras.Sequential([hidden,do, out_2,do,qlayer])\n","    return hybrid_model"],"metadata":{"id":"V8Pq36qlko_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.layers import Dense, Dropout\n","from tensorflow.keras.models import Sequential\n","import pennylane as qml\n","import numpy as np\n","\n","# Define the device for the quantum layer\n","dev = qml.device(\"default.qubit\", wires=3)\n","\n","# Correct the Dropout rate from 0,3 to 0.3\n","do = Dropout(0.3)\n","\n","# Define the quantum neural network\n","@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\n","def quantum_nn(inputs, weights):\n","    print(inputs[0])\n","    # Encode inputs into quantum states\n","    qml.RY(inputs[0], wires=0)\n","    qml.RY(inputs[1], wires=1)\n","    qml.RY(inputs[2], wires=2)\n","\n","    # Parameterized quantum gates\n","    qml.Rot(weights[0] * inputs[3], weights[1] * inputs[4], weights[2] * inputs[5], wires=1)\n","    qml.Rot(weights[3] * inputs[6], weights[4] * inputs[7], weights[5] * inputs[8], wires=2)\n","\n","    # Entangling gates\n","    qml.CNOT(wires=[1, 2])\n","    qml.RY(weights[6], wires=2)\n","    qml.CNOT(wires=[0, 2])\n","    qml.CNOT(wires=[1, 2])\n","\n","    print(\"built\")\n","\n","    # Measure expectation values\n","    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(2))]\n","\n","# Build the hybrid model\n","def hybrid_model():\n","    # Define weight shapes for the quantum layer\n","    weight_shapes = {\"weights\": (7,)}\n","\n","    # Define the quantum Keras layer\n","    qlayer = qml.qnn.KerasLayer(quantum_nn, weight_shapes, output_dim=2)\n","\n","    # Define the classical layers\n","    hidden = Dense(\n","        32,\n","        activation=\"relu\",\n","        kernel_initializer='he_normal',\n","        kernel_regularizer=tf.keras.regularizers.l2(0.01)\n","    )\n","    out_2 = Dense(\n","        9,\n","        activation=\"relu\",\n","        kernel_initializer='he_normal',\n","        kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)\n","    )\n","\n","\n","    out_3 = Dense(\n","        2,\n","        activation=\"relu\",\n","        kernel_initializer='he_normal',\n","        kernel_regularizer=tf.keras.regularizers.l1_l2(l1=0.001, l2=0.001)\n","    )\n","\n","    # Construct the sequential model\n","    model = Sequential([hidden, do, out_2, do,qlayer])\n","    return model\n","\n","# Create dummy X_train data with 15 features\n","num_samples = 90  # For demonstration purposes\n","X_train = np.random.rand(num_samples, 15).astype('float32')\n","\n","# Build and compile the model\n","model = hybrid_model()\n","model.compile(optimizer='adam', loss='mse')\n","\n","# print(output[0])"],"metadata":{"id":"c9_XiiijASW4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uwGdUw2dlTba","executionInfo":{"status":"ok","timestamp":1732113182554,"user_tz":-120,"elapsed":8,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"06249aa6-3658-48af-e7bb-e391c5117bda"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.33416817, 0.4570113 , 0.7913605 , ..., 0.67572916, 0.8719203 ,\n","        0.3107077 ],\n","       [0.16494113, 0.50823504, 0.46302342, ..., 0.25933972, 0.37235272,\n","        0.13594991],\n","       [0.5896279 , 0.2759565 , 0.24129827, ..., 0.7974579 , 0.29604778,\n","        0.5593871 ],\n","       ...,\n","       [0.2396103 , 0.41682413, 0.3932262 , ..., 0.81381345, 0.8443339 ,\n","        0.4086366 ],\n","       [0.17334467, 0.7532806 , 0.37795654, ..., 0.41479996, 0.9777221 ,\n","        0.4702656 ],\n","       [0.70583165, 0.28386775, 0.9448934 , ..., 0.12347304, 0.7984639 ,\n","        0.3674435 ]], dtype=float32)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["outputs = model(X_train)\n","\n","# Print the outputs\n","print(\"Model outputs:\")\n","print(outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"id":"3GzR1ZO2CKsK","executionInfo":{"status":"error","timestamp":1732113182920,"user_tz":-120,"elapsed":372,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"5e7ffc0a-202b-4565-e854-490ca5b40a0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[0.         0.         0.         0.36025834 0.         0.17672184\n"," 0.         0.         0.        ], shape=(9,), dtype=float32)\n","built\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"Exception encountered when calling layer 'keras_layer_3' (type KerasLayer).\n\n{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 9 values, but the requested shape has 90 [Op:Reshape]\n\nCall arguments received by layer 'keras_layer_3' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(90, 9), dtype=float32)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-43-64070ba5956e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print the outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model outputs:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/qnn/keras.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# calculate the forward pass as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluate_qnode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# reshape to the correct number of batch dims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/qnn/keras.py\u001b[0m in \u001b[0;36m_evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# multi-return and batch dim case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;31m# multi-return and no batch dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/qnn/keras.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# multi-return and batch dim case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_prod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;31m# multi-return and no batch dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'keras_layer_3' (type KerasLayer).\n\n{{function_node __wrapped__Reshape_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input to reshape is a tensor with 9 values, but the requested shape has 90 [Op:Reshape]\n\nCall arguments received by layer 'keras_layer_3' (type KerasLayer):\n  • inputs=tf.Tensor(shape=(90, 9), dtype=float32)"]}]},{"cell_type":"code","source":["print(outputs[0][0])"],"metadata":{"id":"g7FoZPd9CNBp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Now exactly what the delloite site say:"],"metadata":{"id":"9seA1Bj1NvmA"}},{"cell_type":"code","source":[],"metadata":{"id":"_fzSB3oiNzLW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Train/Test"],"metadata":{"id":"NV8m_M2blQlc"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","# Example: Define a custom metric\n","def custom_metric(y_true, y_pred):\n","    return tf.reduce_mean(tf.abs(y_true - y_pred))  # Mean Absolute Error (MAE)"],"metadata":{"id":"aLOPvRYvqQq9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hybrid_q_model = hybrid_model()\n","hybrid_q_model.compile(optimizer='adam', loss = 'MSE', metrics = [custom_metric])"],"metadata":{"collapsed":true,"id":"WEfgiaBFlSmX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train_list = np.array(y_train).flatten().tolist()\n","\n","class_counts = np.bincount(y_train_list)\n","class_frequencies = class_counts / float(len(y_train))\n","class_weights = 1 / np.sqrt(class_frequencies)-0.2\n","\n"],"metadata":{"id":"6aUUaHva0ZFB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"C0oDYqGsq7Ph"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}"],"metadata":{"id":"BsVCEV0u1Jzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_weight_dict"],"metadata":{"id":"z8y8qTZM6DJy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_dim = x_train.shape[1]  # Number of columns in x_train\n","hybrid_q_model.build(input_shape=(None, 30))  # Replace `input_dim` with the feature size\n","hybrid_q_model.summary()"],"metadata":{"id":"xlH3Sh4R523A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = hybrid_q_model.fit(x_train, y_train, epochs = 3, batch_size = 200, validation_data=(x_validation, y_validation),shuffle=True)"],"metadata":{"id":"W3AUBSNi2_Cu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# TRY 2"],"metadata":{"id":"4SOwIt4OvsOL"}},{"cell_type":"code","source":["fraud_id = finance_df.Class[finance_df.Class.eq(1)].index\n","nofraud_id = finance_df.Class[finance_df.Class.eq(0)].sample(len(fraud_id)*3).index\n","\n","df_reduced = finance_df.loc[fraud_id.union(nofraud_id)].sample(frac = 1).reset_index( drop = True);"],"metadata":{"id":"k3j-Z28s3Wgh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(fraud_id.shape, nofraud_id.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ny3IWi_3dyQ","executionInfo":{"status":"ok","timestamp":1732111098543,"user_tz":-120,"elapsed":291,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"4033ad27-70d5-408c-d49e-2c42af2afa0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(492,) (1476,)\n"]}]},{"cell_type":"code","source":["df_reduced.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cj5_wNcj3hdO","executionInfo":{"status":"ok","timestamp":1732111113469,"user_tz":-120,"elapsed":295,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"7198707a-cafa-4716-a7b3-fccbc6d7fd2f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1968, 31)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["finance_df=df_reduced"],"metadata":{"id":"KgIEUfUW3ihD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pennylane as qml\n","from pennylane import numpy as np\n","import tensorflow as tf\n","\n","# Define the quantum device\n","dev = qml.device(\"default.qubit\", wires=3)\n","\n","# Define the quantum neural network\n","@qml.qnode(dev, interface=\"tf\", diff_method=\"backprop\")\n","def quantum_nn(inputs, weights):\n","    print(f\"Inputs received: {inputs}\")\n","    print(f\"Weights received: {weights}\")\n","\n","    # Encode inputs into quantum states\n","    qml.RY(inputs[0], wires=0)\n","    qml.RY(inputs[1], wires=1)\n","    qml.RY(inputs[2], wires=2)\n","    print(\"Encoded inputs into quantum states.\")\n","\n","    # Parameterized quantum gates\n","    qml.Rot(weights[0] * inputs[3], weights[1] * inputs[4], weights[2] * inputs[5], wires=1)\n","    qml.Rot(weights[3] * inputs[6], weights[4] * inputs[7], weights[5] * inputs[8], wires=2)\n","    print(\"Applied parameterized quantum gates.\")\n","\n","    # Entangling gates\n","    qml.CNOT(wires=[1, 2])\n","    qml.RY(weights[6], wires=2)\n","    qml.CNOT(wires=[0, 2])\n","    qml.CNOT(wires=[1, 2])\n","    print(\"Added entangling gates.\")\n","\n","    # Measure expectation values\n","    expvals = [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(2))]\n","    print(f\"Measured expectation values: {expvals}\")\n","    return expvals"],"metadata":{"id":"eYc76NmD3ifr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def print_circuit(inputs, weights):\n","    print(\"Printing the quantum circuit...\")\n","    circuit_drawer = qml.draw(quantum_nn)\n","    print(circuit_drawer(inputs, weights))"],"metadata":{"id":"oHFaSmIpNWMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Example inputs and weights\n","inputs = np.random.random(9)  # Replace with actual inputs\n","weights = np.random.random(7)  # Replace with actual weights\n","\n","# Define the model using the functional API\n","input_layer = tf.keras.layers.Input(shape=(9,))\n","\n","dense_layer = tf.keras.layers.Dense(7, activation='relu')(input_layer)\n","\n","# Apply the quantum neural network via a Lambda layer\n","quantum_layer = tf.keras.layers.Lambda(lambda x: tf.stack(quantum_nn(x, weights), axis=-1))(dense_layer)\n","\n","# Output layer: We need to concatenate the two outputs into a single tensor\n","output_layer = tf.keras.layers.Dense(1, activation='sigmoid')(quantum_layer)\n","\n","# Build the model using the functional API\n","model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Debug prints\n","print(\"Model created.\")\n","print_circuit(inputs, weights)"],"metadata":{"id":"eC6-SbDn4yHL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1732117917753,"user_tz":-120,"elapsed":274,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"a67a4765-724f-4654-dac6-f55b03a62219"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs received: Tensor(\"Placeholder:0\", shape=(None, 7), dtype=float32)\n","Weights received: [0.19321466 0.5180692  0.27689942 0.73907562 0.51439225 0.05222705\n"," 0.41112046]\n","Encoded inputs into quantum states.\n","Applied parameterized quantum gates.\n","Added entangling gates.\n","Measured expectation values: [expval(Z(0)), expval(Z(2))]\n","Model created.\n","Printing the quantum circuit...\n","Inputs received: [0.48457208 0.48337721 0.57236355 0.29227794 0.29503232 0.33084619\n"," 0.69705429 0.72817349 0.08799096]\n","Weights received: [0.19321466 0.5180692  0.27689942 0.73907562 0.51439225 0.05222705\n"," 0.41112046]\n","Encoded inputs into quantum states.\n","Applied parameterized quantum gates.\n","Added entangling gates.\n","Measured expectation values: [expval(Z(0)), expval(Z(2))]\n","0: ──RY(0.48)───────────────────────────────────╭●────┤  <Z>\n","1: ──RY(0.48)──Rot(0.06,0.15,0.09)─╭●───────────│──╭●─┤     \n","2: ──RY(0.57)──Rot(0.52,0.37,0.00)─╰X──RY(0.41)─╰X─╰X─┤  <Z>\n"]}]},{"cell_type":"code","source":["# Generate example input data (batch of size 1 with 9 features)\n","example_input = np.random.random((1, 9))  # Replace with actual data as needed\n","\n","# Pass the data through the model\n","output = model.predict(example_input)\n","\n","# Print the input and corresponding output\n","print(f\"Input: {example_input}\")\n","print(f\"Output: {output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"CMF_01UZAXi3","executionInfo":{"status":"error","timestamp":1732117929428,"user_tz":-120,"elapsed":852,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"30722258-b94d-41ba-88bb-9ae50f965036"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs received: Tensor(\"model_9/dense_31/Relu:0\", shape=(None, 7), dtype=float32)\n","Weights received: [0.19321466 0.5180692  0.27689942 0.73907562 0.51439225 0.05222705\n"," 0.41112046]\n","Encoded inputs into quantum states.\n","Applied parameterized quantum gates.\n","Added entangling gates.\n","Measured expectation values: [expval(Z(0)), expval(Z(2))]\n"]},{"output_type":"error","ename":"InvalidArgumentError","evalue":"Graph execution error:\n\nDetected at node 'model_9/lambda_12/strided_slice_1' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n      ColabKernelApp.launch_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-68-dec09b20aba8>\", line 5, in <cell line: 5>\n      output = model.predict(example_input)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/lambda_layer.py\", line 210, in call\n      result = self.function(inputs, **kwargs)\n    File \"<ipython-input-67-6df1aec9e2c2>\", line 11, in <lambda>\n      quantum_layer = tf.keras.layers.Lambda(lambda x: tf.stack(quantum_nn(x, weights), axis=-1))(dense_layer)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 987, in __call__\n      return self._impl_call(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 963, in _impl_call\n      self.construct(args, kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/logging/decorators.py\", line 61, in wrapper_entry\n      return func(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 857, in construct\n      self._qfunc_output = self.func(*args, **kwargs)\n    File \"<ipython-input-66-f97b0d59ee8b>\", line 16, in quantum_nn\n      qml.RY(inputs[1], wires=1)\nNode: 'model_9/lambda_12/strided_slice_1'\nslice index 1 of dimension 0 out of bounds.\n\t [[{{node model_9/lambda_12/strided_slice_1}}]] [Op:__inference_predict_function_8789]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-dec09b20aba8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Pass the data through the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the input and corresponding output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model_9/lambda_12/strided_slice_1' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n      ColabKernelApp.launch_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-68-dec09b20aba8>\", line 5, in <cell line: 5>\n      output = model.predict(example_input)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/core/lambda_layer.py\", line 210, in call\n      result = self.function(inputs, **kwargs)\n    File \"<ipython-input-67-6df1aec9e2c2>\", line 11, in <lambda>\n      quantum_layer = tf.keras.layers.Lambda(lambda x: tf.stack(quantum_nn(x, weights), axis=-1))(dense_layer)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 987, in __call__\n      return self._impl_call(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 963, in _impl_call\n      self.construct(args, kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/logging/decorators.py\", line 61, in wrapper_entry\n      return func(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\", line 857, in construct\n      self._qfunc_output = self.func(*args, **kwargs)\n    File \"<ipython-input-66-f97b0d59ee8b>\", line 16, in quantum_nn\n      qml.RY(inputs[1], wires=1)\nNode: 'model_9/lambda_12/strided_slice_1'\nslice index 1 of dimension 0 out of bounds.\n\t [[{{node model_9/lambda_12/strided_slice_1}}]] [Op:__inference_predict_function_8789]"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":530},"id":"YCtjEdYgPvD8","executionInfo":{"status":"error","timestamp":1732117881411,"user_tz":-120,"elapsed":287,"user":{"displayName":"Epa Douros","userId":"06317381952326479974"}},"outputId":"d15044db-97de-437a-c0d8-e5ab240231ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inputs received: Tensor(\"Placeholder:0\", shape=(None, 9), dtype=float32)\n","Weights received: [0.92048626 0.88384354 0.74917156 0.44352705 0.4254672  0.58196584\n"," 0.97585557]\n"]},{"output_type":"error","ename":"TypeError","evalue":"Exception encountered when calling layer \"lambda_9\" (type Lambda).\n\n'NoneType' object cannot be interpreted as an integer\n\nCall arguments received by layer \"lambda_9\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • mask=None\n  • training=None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-62-8e3d7d45f5be>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Apply the quantum neural network via a Lambda layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mquantum_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-62-8e3d7d45f5be>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Apply the quantum neural network via a Lambda layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mquantum_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquantum_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnode_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impl_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36m_impl_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;31m# construct the tape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0mold_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/logging/decorators.py\u001b[0m in \u001b[0;36mwrapper_entry\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0m_debug_log_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pennylane/workflow/qnode.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mpldb_device_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueuing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAnnotatedQueue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qfunc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQuantumScript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_queue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-62-8e3d7d45f5be>\u001b[0m in \u001b[0;36mquantum_nn\u001b[0;34m(inputs, weights)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Weights received: {weights}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Handle batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mqml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwires\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Exception encountered when calling layer \"lambda_9\" (type Lambda).\n\n'NoneType' object cannot be interpreted as an integer\n\nCall arguments received by layer \"lambda_9\" (type Lambda):\n  • inputs=tf.Tensor(shape=(None, 9), dtype=float32)\n  • mask=None\n  • training=None"]}]}]}